#!/usr/bin/env python3
"""Meeting Analyzer - AI ê¸°ë°˜ íšŒì˜ ë¶„ì„ ë„êµ¬

Usage:
    python analyze.py transcript.txt
    python analyze.py transcript.txt --summary --action-items
    python analyze.py audio.wav --full-analysis
"""

import os
import sys
import argparse
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.core.stt_client import ClovaSpeechClient, ClovaSpeechError
from src.core.formatter import (
    format_segments_to_transcript,
    format_segments_to_detailed_transcript,
    extract_speaker_statistics,
    generate_meeting_summary_header
)
from src.core.ai_analyzer import ReportGenerator, ReportGeneratorError
from src.core.embedding_manager import EmbeddingManager
from dotenv import load_dotenv


def load_config():
    """í™˜ê²½ì„¤ì • ë¡œë“œ"""
    env_path = Path(__file__).parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)
        return True
    else:
        print(f".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {env_path}")
        print(".env.exampleì„ ì°¸ê³ í•˜ì—¬ ì„¤ì •í•˜ì„¸ìš”.")
        return False


def transcribe_if_audio(file_path: str) -> str:
    """ì˜¤ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° ì „ì‚¬ í›„ ëŒ€í™”ë¡ ë°˜í™˜"""
    audio_extensions = {'.wav', '.mp3', '.m4a', '.flac', '.aac', '.webm', '.ogg', '.opus'}
    file_ext = Path(file_path).suffix.lower()

    if file_ext not in audio_extensions:
        # í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()

    print(f"[ì˜¤ë””ì˜¤ íŒŒì¼ ê°ì§€]: {file_path}")
    print("[ë¨¼ì € ì „ì‚¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...]")

    # CLOVA Speech í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        client = ClovaSpeechClient(
            invoke_url=os.getenv("CLOVA_SPEECH_INVOKE_URL"),
            secret_key=os.getenv("CLOVA_SPEECH_SECRET_KEY")
        )
    except Exception as e:
        print(f" CLOVA Speech í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

    # ì „ì‚¬ ì˜µì…˜ (íšŒì˜ì— ìµœì í™”)
    options = {
        'language': 'enko',  # í•œì˜ í˜¼í•© ì¸ì‹
        'completion': 'sync',
        'wordAlignment': True,
        'fullText': True,
        'enable_diarization': True,
        'enable_noise_filtering': True,
        'diarization': {
            'enable': True,
            'speakerCountMin': 2,
            'speakerCountMax': 10
        }
    }

    try:
        result = client.request_by_file(file_path, **options)
        segments = result.get('segments', [])

        if not segments:
            print(" ì „ì‚¬ ê²°ê³¼ì— ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        print(f"[ì „ì‚¬ ì™„ë£Œ]: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        return format_segments_to_transcript(segments)

    except ClovaSpeechError as e:
        print(f" ì „ì‚¬ ì‹¤íŒ¨: {e}")
        return None


def analyze_transcript(transcript: str, analysis_types: list) -> dict:
    """ëŒ€í™”ë¡ AI ë¶„ì„"""
    try:
        generator = ReportGenerator()
    except Exception as e:
        print(f" AI ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("[ì°¸ê³ ] OPENAI_API_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return {}

    results = {}

    try:
        if 'summary' in analysis_types:
            print(f"[í•µì‹¬ ìš”ì•½ ìƒì„± ì¤‘...")
            results['summary'] = generator.summarize(transcript)

        if 'meeting_notes' in analysis_types:
            print(f"[ê³µì‹ íšŒì˜ë¡ ìƒì„± ì¤‘...")
            results['meeting_notes'] = generator.generate_meeting_notes(transcript)

        if 'action_items' in analysis_types:
            print(f"[ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ ì¤‘...")
            results['action_items'] = generator.generate_action_items(transcript)

        if 'sentiment' in analysis_types:
            print(f"[íšŒì˜ ë¶„ìœ„ê¸° ë¶„ì„ ì¤‘...")
            results['sentiment'] = generator.analyze_sentiment(transcript)

        if 'follow_up' in analysis_types:
            print(" í›„ì† ì§ˆë¬¸ ìƒì„± ì¤‘...")
            results['follow_up'] = generator.generate_follow_up_questions(transcript)

        if 'keywords' in analysis_types:
            print("[í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
            results['keywords'] = generator.extract_keywords(transcript)

        if 'topics' in analysis_types:
            print("[ì£¼ì œ ë¶„ë¥˜ ì¤‘...")
            results['topics'] = generator.classify_topics(transcript)

        if 'by_speaker' in analysis_types:
            print("[ë°œì–¸ìë³„ ë¶„ì„ ì¤‘...")
            results['by_speaker'] = generator.analyze_by_speaker(transcript)

        if 'meeting_type' in analysis_types:
            print("[íšŒì˜ ìœ í˜• ë¶„ë¥˜ ì¤‘...")
            results['meeting_type'] = generator.classify_meeting_type(transcript)

        if 'engagement_score' in analysis_types:
            print("[ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚° ì¤‘...")
            results['engagement_score'] = generator.calculate_engagement_score(transcript)

        if 'improvement_suggestions' in analysis_types:
            print("[ê°œì„  ì œì•ˆ ìƒì„± ì¤‘...")
            results['improvement_suggestions'] = generator.generate_improvement_suggestions(transcript)

    except ReportGeneratorError as e:
        print(f" AI ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {}

    return results


def save_analysis_results(input_file: str, transcript: str, analysis_results: dict):
    """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    output_dir = Path("outputs")
    output_dir.mkdir(exist_ok=True)

    base_name = Path(input_file).stem
    timestamp = Path(input_file).name  # For uniqueness

    # Markdown í˜•íƒœë¡œ í†µí•© ë³´ê³ ì„œ ìƒì„±
    report_file = output_dir / f"{base_name}_analysis_report.md"

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"# íšŒì˜ ë¶„ì„ ë³´ê³ ì„œ\n\n")
        f.write(f"**ì›ë³¸ íŒŒì¼**: {input_file}\n")
        f.write(f"**ë¶„ì„ ì¼ì‹œ**: {timestamp}\n\n")
        f.write("---\n\n")

        # ê° ë¶„ì„ ê²°ê³¼ ì‘ì„±
        if 'summary' in analysis_results:
            f.write("## í•µì‹¬ ìš”ì•½\n\n")
            f.write(analysis_results['summary'])
            f.write("\n\n")

        if 'meeting_notes' in analysis_results:
            f.write("## ê³µì‹ íšŒì˜ë¡\n\n")
            f.write(analysis_results['meeting_notes'])
            f.write("\n\n")

        if 'action_items' in analysis_results:
            f.write("## ì•¡ì…˜ ì•„ì´í…œ\n\n")
            f.write(analysis_results['action_items'])
            f.write("\n\n")

        if 'sentiment' in analysis_results:
            f.write("## íšŒì˜ ë¶„ìœ„ê¸° ë¶„ì„\n\n")
            f.write(analysis_results['sentiment'])
            f.write("\n\n")

        if 'follow_up' in analysis_results:
            f.write("##  í›„ì† ì§ˆë¬¸\n\n")
            f.write(analysis_results['follow_up'])
            f.write("\n\n")

        if 'keywords' in analysis_results:
            f.write("## í•µì‹¬ í‚¤ì›Œë“œ\n\n")
            f.write(analysis_results['keywords'])
            f.write("\n\n")

        if 'topics' in analysis_results:
            f.write("## ì£¼ì œ ë¶„ë¥˜\n\n")
            f.write(analysis_results['topics'])
            f.write("\n\n")

        if 'by_speaker' in analysis_results:
            f.write("## ë°œì–¸ìë³„ ë¶„ì„\n\n")
            f.write(analysis_results['by_speaker'])
            f.write("\n\n")

        if 'meeting_type' in analysis_results:
            f.write("## íšŒì˜ ìœ í˜• ë¶„ë¥˜\n\n")
            f.write(analysis_results['meeting_type'])
            f.write("\n\n")

        if 'engagement_score' in analysis_results:
            f.write("## ğŸ“Š ì°¸ì—¬ë„ ì ìˆ˜\n\n")
            f.write(analysis_results['engagement_score'])
            f.write("\n\n")

        if 'improvement_suggestions' in analysis_results:
            f.write("## ğŸ’¡ íšŒì˜ ê°œì„  ì œì•ˆ\n\n")
            f.write(analysis_results['improvement_suggestions'])
            f.write("\n\n")

        # ì›ë³¸ ëŒ€í™”ë¡ ì²¨ë¶€
        f.write("---\n\n")
        f.write("## ì›ë³¸ ëŒ€í™”ë¡\n\n")
        f.write(transcript)

    print(f"[ë¶„ì„ ë³´ê³ ì„œ ì €ì¥: {report_file}")

    # ê°œë³„ ë¶„ì„ ê²°ê³¼ë„ JSONìœ¼ë¡œ ì €ì¥
    import json
    json_file = output_dir / f"{base_name}_analysis.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump({
            'transcript': transcript,
            'analysis': analysis_results
        }, f, indent=2, ensure_ascii=False)
    print(f"[ë¶„ì„ ë°ì´í„° ì €ì¥: {json_file}")

    # ì„ë² ë”© ì €ì¥ (ìš”ì•½ì´ ìˆëŠ” ê²½ìš°)
    if 'summary' in analysis_results:
        try:
            print("\n[ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì¤‘...")
            generator = ReportGenerator()
            embedding_manager = EmbeddingManager()

            meeting_id = base_name
            title = Path(input_file).stem
            summary = analysis_results['summary']

            # ì„ë² ë”© ìƒì„± ë° ì €ì¥
            embedding = generator.generate_embedding(summary)
            embedding_manager.save_meeting_embedding(
                meeting_id=meeting_id,
                title=title,
                summary=summary,
                embedding=embedding
            )

            print(f"[OK] ì„ë² ë”© ì €ì¥ ì™„ë£Œ: {meeting_id}")
        except Exception as e:
            print(f"[WARNING] ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    parser = argparse.ArgumentParser(description="Meeting Analyzer - AI ê¸°ë°˜ íšŒì˜ ë¶„ì„ ë„êµ¬")
    parser.add_argument("input_file", help="ë¶„ì„í•  íŒŒì¼ (í…ìŠ¤íŠ¸ ëŒ€í™”ë¡ ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼)")

    # ë¶„ì„ ìœ í˜• ì„ íƒ
    parser.add_argument("--summary", action="store_true", help="í•µì‹¬ ìš”ì•½ ìƒì„±")
    parser.add_argument("--meeting-notes", action="store_true", help="ê³µì‹ íšŒì˜ë¡ ìƒì„±")
    parser.add_argument("--action-items", action="store_true", help="ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ")
    parser.add_argument("--sentiment", action="store_true", help="íšŒì˜ ë¶„ìœ„ê¸° ë¶„ì„")
    parser.add_argument("--follow-up", action="store_true", help="í›„ì† ì§ˆë¬¸ ìƒì„±")
    parser.add_argument("--keywords", action="store_true", help="í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ")
    parser.add_argument("--topics", action="store_true", help="ì£¼ì œ ë¶„ë¥˜")
    parser.add_argument("--by-speaker", action="store_true", help="ë°œì–¸ìë³„ ë¶„ì„")
    parser.add_argument("--meeting-type", action="store_true", help="íšŒì˜ ìœ í˜• ë¶„ë¥˜")
    parser.add_argument("--engagement-score", action="store_true", help="ì°¸ì—¬ë„ ì ìˆ˜í™”")
    parser.add_argument("--improvement-suggestions", action="store_true", help="íšŒì˜ ê°œì„  ì œì•ˆ")
    parser.add_argument("--full-analysis", action="store_true", help="ì „ì²´ ë¶„ì„ (ëª¨ë“  ìœ í˜•)")

    args = parser.parse_args()

    # í™˜ê²½ì„¤ì • ë¡œë“œ
    if not load_config():
        return 1

    # ì…ë ¥ íŒŒì¼ í™•ì¸
    input_path = Path(args.input_file)
    if not input_path.exists():
        print(f" íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        return 1

    print("Meeting Analyzer")
    print("="*50)
    print(f"ì…ë ¥: {input_path}")

    # ë¶„ì„ ìœ í˜• ê²°ì •
    analysis_types = []
    if args.full_analysis:
        analysis_types = ['summary', 'meeting_notes', 'action_items', 'sentiment', 'follow_up',
                         'keywords', 'topics', 'by_speaker', 'meeting_type',
                         'engagement_score', 'improvement_suggestions']
    else:
        if args.summary:
            analysis_types.append('summary')
        if args.meeting_notes:
            analysis_types.append('meeting_notes')
        if args.action_items:
            analysis_types.append('action_items')
        if args.sentiment:
            analysis_types.append('sentiment')
        if args.follow_up:
            analysis_types.append('follow_up')
        if args.keywords:
            analysis_types.append('keywords')
        if args.topics:
            analysis_types.append('topics')
        if args.by_speaker:
            analysis_types.append('by_speaker')
        if args.meeting_type:
            analysis_types.append('meeting_type')
        if args.engagement_score:
            analysis_types.append('engagement_score')
        if args.improvement_suggestions:
            analysis_types.append('improvement_suggestions')

    # ê¸°ë³¸ê°’: ìš”ì•½ê³¼ ì•¡ì…˜ ì•„ì´í…œ
    if not analysis_types:
        analysis_types = ['summary', 'action_items']

    print(f"[ë¶„ì„ ìœ í˜•]: {', '.join(analysis_types)}")
    print()

    # ëŒ€í™”ë¡ ì¤€ë¹„ (ì˜¤ë””ì˜¤ì¸ ê²½ìš° ì „ì‚¬ ë¨¼ì €)
    transcript = transcribe_if_audio(str(input_path))
    if not transcript:
        return 1

    print(f"[ëŒ€í™”ë¡ ê¸¸ì´: {len(transcript)}ì")
    print()

    # AI ë¶„ì„ ì‹¤í–‰
    analysis_results = analyze_transcript(transcript, analysis_types)
    if not analysis_results:
        return 1

    # ê²°ê³¼ ì €ì¥
    save_analysis_results(str(input_path), transcript, analysis_results)

    # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
    print("\n" + "="*50)
    print(f"[ë¶„ì„ ì™„ë£Œ")
    print("="*50)

    for analysis_type, result in analysis_results.items():
        print(f"\n[{analysis_type.upper()}]:")
        preview = result[:200] + "..." if len(result) > 200 else result
        print(preview)

    print(f"\n[INFO] ì „ì²´ ë¶„ì„ ë³´ê³ ì„œê°€ 'outputs/' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return 0


if __name__ == "__main__":
    exit(main())